<div align="center">

# CNN (Convolutional Neural Networks) - EvriÅŸimli Sinir AÄŸlarÄ± Projesi

### PyTorch ile GÃ¶rÃ¼ntÃ¼ SÄ±nÄ±flandÄ±rma | Hayvan TanÄ±ma Modeli

**Modern CNN mimarisi ile 10 sÄ±nÄ±flÄ± hayvan gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma projesi**

[ HÄ±zlÄ± BaÅŸlangÄ±Ã§](#-hÄ±zlÄ±-baÅŸlangÄ±Ã§) â€¢ [Ã–zellikler](#-proje-Ã¶zellikleri) â€¢ [ Model Mimarisi](#ï¸-model-mimarisi) â€¢ [ SonuÃ§lar](#-sonuÃ§lar) â€¢ [GÃ¶rselleÅŸtirmeler](#-gÃ¶rselleÅŸtirmeler)

---

</div>

##  Projem HakkÄ±nda

Merhaba!  Bu proje, **PyTorch** kÃ¼tÃ¼phanesi kullanÄ±larak **Convolutional Neural Network (CNN)** ile gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma iÅŸlemini gerÃ§ekleÅŸtiren kapsamlÄ± bir derin Ã¶ÄŸrenme projesidir. CNN'ler, Ã¶zellikle gÃ¶rÃ¼ntÃ¼ iÅŸleme ve bilgisayarlÄ± gÃ¶rÃ¼ alanÄ±nda yaygÄ±n olarak kullanÄ±lan derin Ã¶ÄŸrenme modelleridir.

Bu projede, **10 farklÄ± hayvan sÄ±nÄ±fÄ±nÄ±** (kÃ¶pek, kedi, at, fil, kelebek, tavuk, inek, koyun, Ã¶rÃ¼mcek, sincap) ayÄ±rt edebilen bir model eÄŸitiyoruz. Proje, baÅŸlangÄ±Ã§ seviyesinden ileri seviyeye kadar herkesin anlayabileceÄŸi ÅŸekilde adÄ±m adÄ±m aÃ§Ä±klanmÄ±ÅŸtÄ±r.

###  Bu Projede Ã–ÄŸrenecekleriniz

| Konu | AÃ§Ä±klama |
|------|----------|
|  **CNN Mimarisi** | EvriÅŸimli katmanlarÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± ve gÃ¶rÃ¼ntÃ¼lerden Ã¶zellik Ã§Ä±karma sÃ¼recini sinir katmanalarÄ±nÄ± daha iyi anlamÄ±ÅŸ olacak ve  Ã¶ÄŸreneceksiniz |
|  **PyTorch KullanÄ±mÄ±** | PyTorch ile model oluÅŸturma, eÄŸitme ve deÄŸerlendirme iÅŸlemlerini yapmayÄ± Ã¶ÄŸreneceksiniz |
|  **Veri Ã–n Ä°ÅŸleme** | GÃ¶rÃ¼ntÃ¼ verilerinin hazÄ±rlanmasÄ± ve augmentation tekniklerini uygulayacaksÄ±nÄ±z |
|  **Model Optimizasyonu** | HÄ±z ve doÄŸruluk dengesini saÄŸlama tekniklerini Ã¶ÄŸreneceksiniz |
|  **Model DeÄŸerlendirme** | Accuracy, Loss, Confusion Matrix gibi metriklerin nasÄ±l hesaplandÄ±ÄŸÄ±nÄ± gÃ¶receksiniz |
|  **GÃ¶rselleÅŸtirme** | Model tahminlerini ve sonuÃ§larÄ± gÃ¶rsel olarak analiz etmeyi Ã¶ÄŸreneceksiniz |

---

##  Proje Ã–zellikleri

<div align="center">

###  Temel Ã–zellikler

</div>

| Ã–zellik | AÃ§Ä±klama |
|---------|----------|
| **Hedef Accuracy** | **%90+** doÄŸruluk oranÄ± hedefleniyor - Model oldukÃ§a baÅŸarÄ±lÄ±! |
| **HÄ±zlÄ± EÄŸitim** | Optimize edilmiÅŸ batch size (128) ve gÃ¶rÃ¼ntÃ¼ boyutu (160x160) ile hÄ±zlÄ± eÄŸitim |
| **Modern Mimari** | 6 Conv2d katmanÄ±, BatchNorm, Dropout, Global Average Pooling ile gÃ¼Ã§lÃ¼ mimari |
| **Otomatik Ä°ndirme** | KaggleHub ile veri seti otomatik indirilir - HiÃ§ uÄŸraÅŸmadan hazÄ±r! |
| **Data Augmentation** | Random Flip, Rotation, ColorJitter ile overfitting Ã¶nleme |
| **Mixed Precision** | GPU varsa otomatik FP16 eÄŸitimi (2x hÄ±z kazanÄ±mÄ±!) |
| **Early Stopping** | Overfitting Ã¶nleme ve zaman tasarrufu - Model kendini durduruyor |
| **Model Checkpoint** | En iyi model otomatik kaydedilir - `best_model.pth` dosyasÄ± |
| **GÃ¶rselleÅŸtirme** | FotoÄŸraf analizi, bar/pie grafikleri, confusion matrix ile detaylÄ± analiz |

---

## KullanÄ±lan Veri Seti

<div align="center">

### Animals-10 Dataset

</div>

| Ã–zellik | DeÄŸer |
|---------|-------|
| **Dataset** | `alessiocorrado99/animals10` |
| **SÄ±nÄ±f SayÄ±sÄ±** | **10 sÄ±nÄ±f** |
| **Toplam GÃ¶rÃ¼ntÃ¼** | **52,358 gÃ¶rÃ¼ntÃ¼** |
| **SÄ±nÄ±flar** | KÃ¶pek, Kedi, At, Fil, Kelebek, Tavuk, Ä°nek, Koyun, Ã–rÃ¼mcek, Sincap |
| **Kaynak** | KaggleHub (otomatik indirme) |
| **Train/Val Split** | %80 EÄŸitim, %20 DoÄŸrulama |

###  Veri DaÄŸÄ±lÄ±mÄ±

```
SÄ±nÄ±f BaÅŸÄ±na GÃ¶rÃ¼ntÃ¼ SayÄ±larÄ±:
  KÃ¶pek (cane):      9,726 gÃ¶rÃ¼ntÃ¼  (18.6%)
  At (cavallo):       5,246 gÃ¶rÃ¼ntÃ¼  (10.0%)
  Fil (elefante):     2,892 gÃ¶rÃ¼ntÃ¼  (5.5%)
  Kelebek (farfalla): 4,224 gÃ¶rÃ¼ntÃ¼  (8.1%)
  Tavuk (gallina):    6,196 gÃ¶rÃ¼ntÃ¼  (11.8%)
  Kedi (gatto):       3,336 gÃ¶rÃ¼ntÃ¼  (6.4%)
  Ä°nek (mucca):       3,732 gÃ¶rÃ¼ntÃ¼  (7.1%)
  Koyun (pecora):     3,640 gÃ¶rÃ¼ntÃ¼  (7.0%)
  Ã–rÃ¼mcek (ragno):    9,642 gÃ¶rÃ¼ntÃ¼  (18.4%)
  Sincap (scoiattolo): 3,724 gÃ¶rÃ¼ntÃ¼  (7.1%)
```

>  **Not:** Veri seti dengeli deÄŸil, bazÄ± sÄ±nÄ±flar daha fazla gÃ¶rÃ¼ntÃ¼ye sahip. Bu durum model eÄŸitimini etkileyebilir, ancak data augmentation ile bu sorunu minimize ediyoruz.

---

##  Model Mimarisi

<div align="center">

###  CNN Katman YapÄ±sÄ±

</div>

```
1. GiriÅŸ ve Ä°lk Ã–zellik Ã‡Ä±karÄ±mÄ± (Blok 1): GÃ¶rÃ¼ntÃ¼yÃ¼ modele verdiÄŸimiz ilk aÅŸamada, 3 renk kanalÄ±nÄ± alÄ±p doÄŸrudan 64 kanala Ã§Ä±karÄ±yoruz. Burada boyutu biraz dÃ¼ÅŸÃ¼rÃ¼p iÅŸlem yÃ¼kÃ¼nÃ¼ azaltmak iÃ§in "Stride=2" kullandÄ±m. EÄŸitim daha kararlÄ± ilerlesin diye her conv iÅŸleminden sonra mutlaka Batch Normalization ve ReLU aktivasyonunu ekledim. BloÄŸun sonunda, hem boyutu kÃ¼Ã§Ã¼ltmek hem de modelin ezberlemesini (overfitting) engellemek iÃ§in Max Pooling ve Dropout katmanlarÄ±nÄ± devreye soktuk.

2. DerinleÅŸme AÅŸamasÄ± (Blok 2): Modelin biraz daha karmaÅŸÄ±k detaylarÄ± Ã¶ÄŸrenmesi iÃ§in ikinci blokta kanal sayÄ±sÄ±nÄ± 64â€™ten 128â€™e yÃ¼kselttim. YapÄ± olarak ilk blokla benzer ilerliyor; yine stride ile boyut dÃ¼ÅŸÃ¼rme, ardÄ±ndan normalizasyon ve aktivasyon iÅŸlemleri var. Ä°kinci bir 128â€™lik evriÅŸimden sonra yine havuzlama (pooling) yaparak veriyi bir sonraki aÅŸamaya hazÄ±rlÄ±yoruz.

3. Ãœst DÃ¼zey Ã–znitelikler (Blok 3): Son evriÅŸim bloÄŸunda artÄ±k kanal sayÄ±sÄ±nÄ± 256â€™ya kadar Ã§Ä±kardÄ±k. Buradaki amaÃ§, gÃ¶rseldeki daha soyut ve Ã¼st dÃ¼zey Ã¶zellikleri yakalayabilmek. Klasik Conv+BN+ReLU zincirinden sonra son bir pooling ve dropout uygulayarak Ã¶znitelik Ã§Ä±karma iÅŸlemini tamamladÄ±k.

4. SÄ±nÄ±flandÄ±rma (Classifier): SonuÃ§ kÄ±smÄ±nda klasik dÃ¼zleÅŸtirme (flatten) yerine, parametre sayÄ±sÄ±nÄ± ÅŸiÅŸirmemek iÃ§in Global Average Pooling kullandÄ±m; bu sayede elimizde 1x1x256 boyutunda temiz bir vektÃ¶r kaldÄ±. Bunu Tam BaÄŸlÄ± (Linear) katmana vererek nÃ¶ron sayÄ±sÄ±nÄ± 128â€™e indirdim. Burada modelin veriye aÅŸÄ±rÄ± uyum saÄŸlamasÄ±nÄ± Ã¶nlemek iÃ§in %50 oranÄ±nda bir Dropout ekledim. En sonda da 10 farklÄ± sÄ±nÄ±fÄ±mÄ±z olduÄŸu iÃ§in Ã§Ä±kÄ±ÅŸ katmanÄ±nÄ± 10 nÃ¶rona baÄŸlayarak mimariyi tamamladÄ±m.
```

### Model DetaylarÄ±

| Katman | Parametreler | AÃ§Ä±klama |
|--------|--------------|----------|
| **Conv2d Layers** | 6 katman | Ã–zellik Ã§Ä±karma (3â†’64â†’128â†’256) - Her katmanda daha fazla Ã¶zellik Ã¶ÄŸreniyoruz |
| **BatchNorm2d** | Her Conv2d'den sonra | EÄŸitimi stabilize eder - Daha hÄ±zlÄ± ve kararlÄ± Ã¶ÄŸrenme |
| **MaxPool2d** | 3 katman | Boyut azaltma (160â†’80â†’40â†’20) - Hesaplama maliyetini dÃ¼ÅŸÃ¼rÃ¼r |
| **Dropout** | 0.25 (Conv), 0.5 (FC) | Overfitting Ã¶nleme - Modelin ezberlemesini engeller |
| **Global Avg Pooling** | 1 katman | Ã–zellik haritasÄ±nÄ± indirgeme - Parametre sayÄ±sÄ±nÄ± azaltÄ±r |
| **Fully Connected** | 2 katman | SÄ±nÄ±flandÄ±rma (256â†’128â†’10) - Son kararÄ± veren katmanlar |
| **Toplam Parametre** | **~1.18M** | Hafif ve hÄ±zlÄ± model - GPU olmadan da Ã§alÄ±ÅŸabilir |

>  **Ã–ÄŸrenci Notu:** Model oldukÃ§a hafif (1.18M parametre), bu sayede hem hÄ±zlÄ± eÄŸitiliyor hem de daha az bellek kullanÄ±yor. `stride=2` kullanarak bazÄ± Conv2d katmanlarÄ±nda boyut azaltma yapÄ±yoruz, bu da eÄŸitimi hÄ±zlandÄ±rÄ±yor.

---

## HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1. Gereksinimler

#### Conda Environment 

Conda kullanmak daha kolay ve gÃ¼venilir. Ä°ÅŸte adÄ±m adÄ±m:

```bash
# 1. Environment oluÅŸtur (environment.yaml dosyasÄ±ndan)
conda env create -f environment.yaml

# 2. Environment'Ä± aktifleÅŸtir
conda activate cnn_project_env

# 3. Jupyter kernel'i yÃ¼kle (notebook'ta Ã§alÄ±ÅŸtÄ±rmak iÃ§in)
python -m ipykernel install --user --name cnn_project_env --display-name "CNN Project"
```

> **Not:** EÄŸer `environment.yaml` dosyasÄ± yoksa, aÅŸaÄŸÄ±daki pip kurulumunu kullanabilirsiniz.

#### Pip ile Kurulum

```bash
# TÃ¼m gereksinimleri yÃ¼kle
pip install -r requirements.txt

# Jupyter notebook'u baÅŸlatmak iÃ§in
pip install jupyter notebook
```

#### Gereksinimler Listesi

Projede kullanÄ±lan ana kÃ¼tÃ¼phaneler:

- **PyTorch** (â‰¥2.0.0) - Derin Ã¶ÄŸrenme framework'Ã¼
- **torchvision** (â‰¥0.15.0) - GÃ¶rÃ¼ntÃ¼ dÃ¶nÃ¼ÅŸÃ¼mleri
- **numpy** (â‰¥1.24.0) - SayÄ±sal hesaplamalar
- **matplotlib** (â‰¥3.7.0) - Grafik Ã§izimi
- **seaborn** (â‰¥0.12.0) - Ä°statistiksel gÃ¶rselleÅŸtirme
- **scikit-learn** (â‰¥1.3.0) - Model deÄŸerlendirme metrikleri
- **Pillow** (â‰¥10.0.0) - GÃ¶rÃ¼ntÃ¼ iÅŸleme
- **kagglehub** (â‰¥0.3.0) - Kaggle veri seti indirme
- **tqdm** (â‰¥4.65.0) - Ä°lerleme Ã§ubuÄŸu
- **jupyter** (â‰¥1.0.0) - Notebook ortamÄ±

### 2. Kaggle API Kurulumu Kurma

Kaggle veri setini indirmek iÃ§in API anahtarÄ± profil kÄ±smÄ±ndan alabilirsiin orda generate yeri var ordan oluÅŸturabilirsiniz ya da aÅŸaÄŸÄ±daki adÄ±malrÄ± yapabilirsiniz. 

**AdÄ±m AdÄ±m:**

1. **[Kaggle](https://www.kaggle.com/)** hesabÄ±nÄ±za giriÅŸ yapÄ±n (yoksa Ã¼cretsiz kaydolun)
2. SaÄŸ Ã¼st kÃ¶ÅŸedeki profil resminize tÄ±klayÄ±n
3. **Account Settings** > **API** bÃ¶lÃ¼mÃ¼ne tÄ±klayÄ±n
4. **Create New Token** butonuna tÄ±klamanÄ±z gerekiyor
5. `kaggle.json` dosyasÄ± otomatik indirilecek

**DosyayÄ± YerleÅŸtirme:**

- **Linux/Mac**: 
  ```bash
  mkdir -p ~/.kaggle
  mv ~/Downloads/kaggle.json ~/.kaggle/
  chmod 600 ~/.kaggle/kaggle.json
  ```

- **Windows**: 
  ```
  C:\Users\<kullanÄ±cÄ±_adÄ±>\.kaggle\kaggle.json
  ```
  (KlasÃ¶r yoksa oluÅŸturun)

> âš ï¸ **Ã–nemli:** `kaggle.json` dosyasÄ± ÅŸu formatta olmalÄ±:
> ```json
> {"username":"your_username","key":"your_api_key"}
> ```

### 3. Notebook'u Ã‡alÄ±ÅŸtÄ±rma

```bash
# Jupyter Notebook'u baÅŸlat
jupyter notebook

# veya JupyterLab (daha modern arayÃ¼z)
jupyter lab
```

**Notebook'ta Ã‡alÄ±ÅŸtÄ±rma:**

1. `cnn_classification_project.ipynb` dosyasÄ±nÄ± aÃ§Ä±n
2. **Kernel > Restart & Run All** ile tÃ¼m hÃ¼creleri sÄ±rayla Ã§alÄ±ÅŸtÄ±rÄ±n
3. Veya her hÃ¼creyi tek tek Ã§alÄ±ÅŸtÄ±rabilirsiniz (Ã¶ÄŸrenmek iÃ§in daha iyi!)

> **Ä°pucu:** Ä°lk Ã§alÄ±ÅŸtÄ±rmada veri seti indirilicek beyaz bir histbar grafiÄŸi Ã§Ä±kÄ±cak MB ya da GB ise orda o histbar grafiÄŸi yÃ¼klenirken gÃ¶rebilirsiniz. 

---

## Notebook Ä°Ã§eriÄŸi

Notebook ÅŸu bÃ¶lÃ¼mlerden oluÅŸmaktadÄ±r. Her bÃ¶lÃ¼m detaylÄ± aÃ§Ä±klamalarla birlikte geliyor:

| # | BÃ¶lÃ¼m | AÃ§Ä±klama | Ne Ã–ÄŸreneceksiniz? |
|---|-------|----------|-------------------|
| 1ï¸ | **KÃ¼tÃ¼phanelerin Ä°Ã§e AktarÄ±lmasÄ±** | Gerekli Python kÃ¼tÃ¼phanelerinin yÃ¼klenmesi | PyTorch, torchvision, matplotlib gibi kÃ¼tÃ¼phanelerin ne iÅŸe yaradÄ±ÄŸÄ±nÄ± |
| 2ï¸| **Veri Setinin Ä°ndirilmesi** | KaggleHub ile veri setini otomatik indirme | Kaggle API kullanÄ±mÄ±nÄ± ve veri seti yapÄ±sÄ±nÄ± |
| 3ï¸| **Veri Ã–n Ä°ÅŸleme** | GÃ¶rÃ¼ntÃ¼lerin hazÄ±rlanmasÄ± ve train/validation split | GÃ¶rÃ¼ntÃ¼ dÃ¶nÃ¼ÅŸÃ¼mlerini ve veri bÃ¶lme tekniklerini |
| 4ï¸| **PyTorch CNN Modeli** | CNN model mimarisinin oluÅŸturulmasÄ± | CNN katmanlarÄ±nÄ± ve model yapÄ±sÄ±nÄ± |
| 5ï¸| **Model EÄŸitimi** | Modelin eÄŸitilmesi ve hyperparameter ayarlarÄ± | EÄŸitim sÃ¼recini, loss hesaplamayÄ±, optimizer'larÄ± |
| 6ï¸| **Model DeÄŸerlendirme** | Model performansÄ±nÄ±n Ã¶lÃ§Ã¼lmesi | Accuracy, precision, recall, F1-score metriklerini |
| 7ï¸| **SonuÃ§lar ve GÃ¶rselleÅŸtirme** | Loss/Accuracy grafikleri, fotoÄŸraf analizi, sÄ±nÄ±f grafikleri | Model sonuÃ§larÄ±nÄ± gÃ¶rselleÅŸtirmeyi ve analiz etmeyi |
| 8ï¸| **Confusion Matrix** | KarÄ±ÅŸÄ±klÄ±k matrisi gÃ¶rselleÅŸtirmesi | Modelin hangi sÄ±nÄ±flarÄ± karÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ± anlamayÄ± |

---

## CNN ve Teknik Detaylar

<div align="center">

### Hyperparameter'lar
Hyperparametreler Ã¶nemi belirli koÅŸullarÄ± ya da sayÄ±larÄ± girdiÄŸimizde bize daha iyi bir sonuÃ§ Ã§Ä±karmasÄ± iÃ§in kullandÄ±ÄŸÄ±mÄ±z parametrelerdir.
</div>

| Parametre | DeÄŸer | AÃ§Ä±klama |
|-----------|-------|----------|
| **GÃ¶rÃ¼ntÃ¼ Boyutu** | `160x160` | HÄ±z iÃ§in optimize edilmiÅŸ (224 yerine 160 kullanÄ±yoruz) |
| **Batch Size** | `128` | HÄ±zlÄ± eÄŸitim iÃ§in (GPU varsa daha bÃ¼yÃ¼k yapabilirsiniz) |
| **Epoch SayÄ±sÄ±** | `25` | Early Stopping ile optimize (genelde 15-20 epoch'da durur) |
| **Learning Rate** | `0.002` | Adam optimizer iÃ§in (otomatik ayarlanÄ±yor) |
| **Weight Decay** | `1e-4` | Regularization (overfitting Ã¶nleme) |
| **Early Stopping** | `patience=7` | 7 epoch iyileÅŸme olmazsa durur |
| **Train/Val Split** | `80/20` | Standart split oranÄ± (41,886 train, 10,472 validation) |

### Data Augmentation

Data augmentation, modelin daha fazla Ã§eÅŸitlilik gÃ¶rmesini saÄŸlar ve overfitting'i Ã¶nler:

| Teknik | Parametre | AmaÃ§ | Ne Ä°ÅŸe Yarar? |
|--------|-----------|------|---------------|
| **RandomHorizontalFlip** | `p=0.5` | Yatay Ã§evirme | GÃ¶rÃ¼ntÃ¼yÃ¼ ayna gibi Ã§evirir (kÃ¶pek soldan veya saÄŸdan gelebilir) |
| **RandomRotation** | `10Â°` | DÃ¶ndÃ¼rme | GÃ¶rÃ¼ntÃ¼yÃ¼ hafifÃ§e dÃ¶ndÃ¼rÃ¼r (farklÄ± aÃ§Ä±lardan Ã¶ÄŸrenir) |
| **ColorJitter** | `brightness=0.15, contrast=0.15, saturation=0.15` | Renk deÄŸiÅŸimi | AydÄ±nlatma farklÄ±lÄ±klarÄ±na karÅŸÄ± dayanÄ±klÄ±lÄ±k saÄŸlar |
| **Normalize** | ImageNet mean/std | Standart normalizasyon | GÃ¶rÃ¼ntÃ¼leri ImageNet standartlarÄ±na gÃ¶re normalize eder |

> **Ã–ÄŸrenci Notu:** Data augmentation sadece eÄŸitim sÄ±rasÄ±nda uygulanÄ±r, validation/test sÄ±rasÄ±nda uygulanmaz. Bu sayede model gerÃ§ek dÃ¼nya performansÄ±nÄ± daha iyi yansÄ±tÄ±r.

### Optimizasyon Teknikleri

Projede kullanÄ±lan optimizasyon teknikleri:

-  **Mixed Precision Training** (FP16) - GPU varsa otomatik 2x hÄ±z kazanÄ±mÄ±
-  **Learning Rate Scheduling** - ReduceLROnPlateau ile otomatik Ã¶ÄŸrenme hÄ±zÄ± ayarlama
-  **Model Checkpointing** - En iyi model otomatik kaydedilir (`best_model.pth`)
-  **Early Stopping** - Overfitting Ã¶nleme ve zaman tasarrufu
-  **Adam Optimizer** - Otomatik Ã¶ÄŸrenme hÄ±zÄ± ayarlama

---

##  SonuÃ§lar

###  Hedefler

| Metrik | Hedef | Durum | AÃ§Ä±klama |
|--------|-------|-------|----------|
| **Accuracy** | **â‰¥ %90** |  Hedeflemekteydim | Modelin doÄŸru tahmin yÃ¼zdesi |
| **Loss** | **< 0.5** |  Hedeflemekteydim | Modelin hata deÄŸeri (ne kadar dÃ¼ÅŸÃ¼k o kadar iyi) |

###  Ã‡Ä±ktÄ±lar

EÄŸitim tamamlandÄ±ÄŸÄ±nda otomatik olarak oluÅŸturulur:

-  **Loss Grafikleri** (2 adet: Train+Val, Train Only)
-  **Accuracy Grafikleri** (2 adet: Train+Val, Val Only)
-  **Model Tahmin GÃ¶rselleÅŸtirmesi** (16 gÃ¶rÃ¼ntÃ¼ ile fotoÄŸraf analizi)
-  **SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± Grafikleri** (Bar ve Pie grafikleri)
-  **Classification Report** (Precision, Recall, F1-Score)
-  **Confusion Matrix** (GÃ¶rsel performans analizi)
-  **Best Model** (`best_model.pth` dosyasÄ±)

---

## GÃ¶rselleÅŸtirmeler

Projede oluÅŸturulan gÃ¶rselleÅŸtirmeler:

### 1. Train/Validation Grafikleri

![Train/Validation Grafikleri](fotolar/train_validation_graphic.png)

Loss ve Accuracy grafikleri ile modelin eÄŸitim sÃ¼recini takip edebilirsiniz. Overfitting olup olmadÄ±ÄŸÄ±nÄ± bu grafiklerden anlayabilirsiniz.

### 2. Model Tahmin GÃ¶rselleÅŸtirmesi

![Model FotoÄŸraf Tahminleri](fotolar/model_photo_predicts.png)

Modelin gerÃ§ek gÃ¶rÃ¼ntÃ¼ler Ã¼zerindeki tahminlerini gÃ¶rselleÅŸtirir. YeÅŸil kenarlÄ±k = DoÄŸru tahmin âœ…, KÄ±rmÄ±zÄ± kenarlÄ±k = YanlÄ±ÅŸ tahmin âŒ

### 3. SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± - Bar GrafiÄŸi

![SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± Bar GrafiÄŸi](fotolar/classes_bar_graph.png)

Her sÄ±nÄ±fta kaÃ§ gÃ¶rÃ¼ntÃ¼ olduÄŸunu gÃ¶sterir. Veri setinin dengesizliÄŸini bu grafikten gÃ¶rebilirsiniz.

### 4. SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± - Pie GrafiÄŸi

![SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± Pie GrafiÄŸi](fotolar/pie_classes.png)

SÄ±nÄ±flarÄ±n toplam iÃ§indeki oranÄ±nÄ± gÃ¶sterir. Hangi sÄ±nÄ±flarÄ±n daha fazla veriye sahip olduÄŸunu gÃ¶rsel olarak anlayabilirsiniz.

### 5. Confusion Matrix

![Confusion Matrix](fotolar/matrix_graphic.png)

Modelin hangi sÄ±nÄ±flarÄ± karÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ± gÃ¶sterir. KÃ¶ÅŸegen Ã¼zerindeki deÄŸerler doÄŸru tahminleri, diÄŸerleri yanlÄ±ÅŸ tahminleri gÃ¶sterir.

### 6. Metrikler

![Metrikler](fotolar/metrics.png)

Model performans metriklerini gÃ¶sterir. Accuracy, Loss, Precision, Recall gibi deÄŸerleri buradan gÃ¶rebilirsiniz.

---

##  Proje YapÄ±sÄ±

```
 cnn-classification-project
â”‚
â”œâ”€â”€ cnn_classification_project.ipynb  # Ana notebook (tÃ¼m kod)
â”œâ”€â”€ environment.yaml                  # Conda environment dosyasÄ±
â”œâ”€â”€  requirements.txt                   # Pip requirements
â”œâ”€â”€ README.md                          # Bu dosya (proje dokÃ¼mantasyonu)
â”œâ”€â”€ .gitignore                         # Git ignore dosyasÄ±
â”‚
â”œâ”€â”€ ğŸ“ fotolar/                           # GÃ¶rselleÅŸtirme gÃ¶rselleri
â”‚   â”œâ”€â”€ train_validation_graphic.png
â”‚   â”œâ”€â”€ model_photo_predicts.png
â”‚   â”œâ”€â”€ classes_bar_graph.png
â”‚   â”œâ”€â”€ pie_classes.png
â”‚   â”œâ”€â”€ matrix_graphic.png
â”‚   â””â”€â”€ metrics.png
â”‚
â”œâ”€â”€ best_model.pth                     # En iyi model (eÄŸitim sonrasÄ±)
â””â”€â”€ Grafikler ve sonuÃ§lar              # Notebook Ã§Ä±ktÄ±larÄ±
```

---

## GitHub'a YÃ¼kleme iÃ§in  Git Bash KomutlarÄ±

### Ä°lk Kurulum AyarlarÄ±nÄ± yapmak.

```bash
# 1. Git repository'sini baÅŸlat
git init

# 2. TÃ¼m dosyalarÄ± ekle
git add .

# 3. Ä°lk commit
git commit -m " Initial commit: CNN Classification Project"

# 4. GitHub repository'sine baÄŸla (Ã¶nce GitHub'da repo oluÅŸturun!)
git remote add origin https://github.com/kullanici_adi/cnn-project.git

# 5. Push yap
git push -u origin main
```

###  GÃ¼ncelleme

```bash
# DeÄŸiÅŸiklikleri ekle
git add .

# Commit yap
git commit -m " Update: Model improvements"

# Push yap
git push
```

> **Ä°pucu:** `.gitignore` dosyasÄ±nda `best_model.pth` ve `data/` klasÃ¶rÃ¼ ignore edilmiÅŸtir (Ã§ok bÃ¼yÃ¼k dosyalar). Sadece kod ve dokÃ¼mantasyon GitHub'a yÃ¼klenir.

---

##  Ã–ÄŸrenilen Kavramlar

Bu projede ÅŸunlarÄ± Ã¶ÄŸreneceksiniz:

- **CNN Mimarisi**: EvriÅŸimli katmanlar, pooling, fully connected layers
- **PyTorch**: Model oluÅŸturma, eÄŸitme, deÄŸerlendirme
- **Veri Ã–n Ä°ÅŸleme**: GÃ¶rÃ¼ntÃ¼ dÃ¶nÃ¼ÅŸÃ¼mleri, augmentation
- **Optimizasyon**: Learning rate scheduling, early stopping
- **Model DeÄŸerlendirme**: Accuracy, Loss, Confusion Matrix
- **Overfitting/Underfitting**: Kavramlar ve Ã¶nleme teknikleri
- **GÃ¶rselleÅŸtirme**: Grafik Ã§izimi ve sonuÃ§ analizi

---

##  Ä°yileÅŸtirme Ã–nerileri

###  Performans Ä°yileÅŸtirmeleri

EÄŸer model performansÄ±nÄ± daha da artÄ±rmak isterseniz:

1. **Transfer Learning** 
   - ResNet, EfficientNet, MobileNet gibi Ã¶nceden eÄŸitilmiÅŸ modeller kullanÄ±n
   - ImageNet'te eÄŸitilmiÅŸ modeller daha iyi Ã¶zellik Ã§Ä±karabilir
   - Daha az veriyle daha iyi sonuÃ§lar alabilirsiniz

2. **Daha Fazla Data Augmentation** 
   - Random Crop, Random Erasing, MixUp gibi teknikler ekleyin
   - Modelin farklÄ± gÃ¶rÃ¼ntÃ¼ varyasyonlarÄ±nÄ± Ã¶ÄŸrenmesini saÄŸlar
   - Overfitting'i daha iyi Ã¶nler

3. **Hyperparameter Tuning** 
   - Grid Search veya Random Search kullanÄ±n
   - Learning rate, batch size, dropout oranlarÄ± optimize edin
   - Optuna gibi kÃ¼tÃ¼phaneler kullanabilirsiniz

4. **Ensemble Methods** 
   - Birden fazla modeli birleÅŸtirin
   - Her model farklÄ± tahmin yapar, sonuÃ§lar birleÅŸtirilir
   - Daha yÃ¼ksek accuracy saÄŸlar

5. **Daha Derin Modeller** 
   - Residual connections (ResNet benzeri) kullanÄ±n
   - Daha fazla katman ekleyin (ancak overfitting riski artar)
   - Attention mekanizmalarÄ± ekleyebilirsiniz

---

##  Sorun Giderme

###  Kaggle API HatasÄ± (403)

**Sorun**: `403 Client Error` alÄ±yorsunuz

**Ã‡Ã¶zÃ¼m**:
1. Kaggle hesabÄ±nÄ±zdan API token oluÅŸturun
2. `kaggle.json` dosyasÄ±nÄ± doÄŸru konuma koyun
3. Dosya izinlerini kontrol edin (Linux/Mac: `chmod 600 ~/.kaggle/kaggle.json`)
4. Dosya formatÄ±nÄ± kontrol edin (JSON formatÄ±nda olmalÄ±)

###  CUDA Out of Memory

**Sorun**: GPU bellek hatasÄ± alÄ±yorsunuz

**Ã‡Ã¶zÃ¼m**:
- Batch size'Ä± kÃ¼Ã§Ã¼ltÃ¼n (128 â†’ 64 veya 32)
- GÃ¶rÃ¼ntÃ¼ boyutunu kÃ¼Ã§Ã¼ltÃ¼n (160 â†’ 128)
- Mixed Precision Training kullanÄ±n (otomatik aktif)

###  Model Accuracy DÃ¼ÅŸÃ¼k

**Sorun**: Model %90'a ulaÅŸamÄ±yor

**Ã‡Ã¶zÃ¼m**:
- Daha fazla epoch eÄŸitin (25 â†’ 50)
- Learning rate'i ayarlayÄ±n (0.002 â†’ 0.001 veya 0.003)
- Data augmentation'Ä± artÄ±rÄ±n
- Transfer learning deneyin
- Model mimarisini bÃ¼yÃ¼tÃ¼n

###  Veri Seti BulunamadÄ±

**Sorun**: Veri seti indirilemiyor

**Ã‡Ã¶zÃ¼m**:
1. Kaggle API anahtarÄ±nÄ±zÄ± kontrol edin
2. Ä°nternet baÄŸlantÄ±nÄ±zÄ± kontrol edin
3. Kaggle hesabÄ±nÄ±zÄ±n aktif olduÄŸundan emin olun
4. Veri seti adÄ±nÄ± kontrol edin (`alessiocorrado99/animals10`)

---

##  Notlar

-  Model dosyasÄ± (`best_model.pth`) otomatik kaydedilir
-  Veri seti ilk Ã§alÄ±ÅŸtÄ±rmada otomatik indirilir
-  Model eÄŸitimi Early Stopping ile optimize edilir
-  Mixed Precision Training CUDA varsa otomatik aktif olur
-  **Hedef: Loss < 0.5, Accuracy >= 90%**
-  TÃ¼m gÃ¶rselleÅŸtirmeler otomatik oluÅŸturulur
-  Notebook'ta her bÃ¶lÃ¼m detaylÄ± aÃ§Ä±klamalarla gelir

---

##  KatkÄ±da Bulunma

Bu proje eÄŸitim amaÃ§lÄ±dÄ±r. Ä°yileÅŸtirmeler yapmak isterseniz:

1. Fork yapÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. Commit yapÄ±n (`git commit -m 'Add amazing feature'`)
4. Push yapÄ±n (`git push origin feature/amazing-feature`)
5. Pull Request aÃ§Ä±n

---.
<div align="center">

### Bu proje hakkÄ±nda dÃ¼ÅŸÃ¼ncelerinizi bekliyorum Tavsiyelerede aÃ§Ä±ÄŸÄ±m.





</div>

